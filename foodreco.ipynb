{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Classify the data set into the train and test data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Set the path to your original dataset directory\n",
    "dataset_dir = './Ingredients'\n",
    "\n",
    "# Set the path to the directory where you want to create the training and testing directories\n",
    "output_dir = './output'\n",
    "\n",
    "# Set the desired split ratio (e.g., 0.8 for 80% training and 20% testing)\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Create the training and testing directories\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "test_dir = os.path.join(output_dir, 'test')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "# Iterate over the image files in the original dataset directory\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    for image in os.listdir(os.path.join(dataset_dir,filename)):\n",
    "        if image.endswith('.jpeg'):\n",
    "            # Split the image to extract the ingredient name and image number\n",
    "            parts = image.split('_')\n",
    "            ingredient_name = parts[0]\n",
    "            image_number = int(parts[1].split('.')[0])\n",
    "\n",
    "            # Create the class directories in the training and testing directories\n",
    "            train_class_dir = os.path.join(train_dir, ingredient_name)\n",
    "\n",
    "            test_class_dir = os.path.join(test_dir, ingredient_name)\n",
    "            os.makedirs(train_class_dir, exist_ok=True)\n",
    "            os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "            # Split the images into training and testing sets based on the image number\n",
    "            if image_number <= train_ratio * 10:\n",
    "                # Move the image to the training class directory\n",
    "                src_path = os.path.join(os.path.join(dataset_dir,filename), image)\n",
    "                dst_path = os.path.join(train_class_dir, image)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "            else:\n",
    "                # Move the image to the testing class directory\n",
    "                src_path = os.path.join(os.path.join(dataset_dir,filename), image)\n",
    "                dst_path = os.path.join(test_class_dir, image)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **resize  and normalize the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "habeshagomen_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DFB3280>\n",
      "habeshagomen_14.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "habeshagomen_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "habeshagomen_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-habeshagomen_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2A6E0>\n",
      "augmented-habeshagomen_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "habeshagomen_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "habeshagomen_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "habeshagomen_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-habeshagomen_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "habeshagomen_3.jpg\n",
      "augmented-habeshagomen_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "habeshagomen_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-habeshagomen_14.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "habeshagomen_15.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-habeshagomen_13.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-habeshagomen_3.jpg\n",
      "habeshagomen_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "habeshagomen_13.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-habeshagomen_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-habeshagomen_12.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-habeshagomen_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-habeshagomen_15.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "habeshagomen_12.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-habeshagomen_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-erd_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "erd_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "erd_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "erd_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "erd_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "erd_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-erd_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-erd_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-erd_9.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-erd_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "erd_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF20>\n",
      "augmented-erd_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-erd_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "erd_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-erd_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "erd_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "erd_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "erd_9.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-mekoreni_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_13.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-mekoreni_14.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-mekoreni_9.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "mekoreni_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_9.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "mekoreni_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_14.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "mekoreni_11.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "mekoreni_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_12.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_11.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_12.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "augmented-mekoreni_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mekoreni_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-mekoreni_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "mekoreni_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "mekoreni_13.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-sigaatint_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "sigaatint_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-sigaatint_20.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "sigaatint_11.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-sigaatint_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "sigaatint_15.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_20.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "sigaatint_9.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_18.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "sigaatint_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "augmented-sigaatint_9.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_14.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_19.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "sigaatint_14.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_18.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_11.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "sigaatint_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AF80>\n",
      "sigaatint_16.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "augmented-sigaatint_10.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "sigaatint_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_15.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "augmented-sigaatint_19.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_16.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "sigaatint_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "augmented-sigaatint_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "fish_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "aterkik_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "aterkik_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "aterkik_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "aterkik_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "aterkik_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "aterkik_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "aterkik_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "beso_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "beso_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "beso_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "beso_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "beso_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "beso_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "beso_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "beso_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "injera_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "injera_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "injera_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B040>\n",
      "injera_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "injera_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "injera_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "injera_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "injera_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "pasta_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "pasta_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "pasta_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "pasta_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "pasta_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "pasta_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "pasta_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "misir_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "misir_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "misir_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "misir_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "misir_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "misir_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "misir_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "misir_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "dfinmisir_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "dfinmisir_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "dfinmisir_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "dfinmisir_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "shirofloor_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "shirofloor_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "shirofloor_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "shirofloor_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "shirofloor_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "shirofloor_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "shirofloor_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "shirofloor_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "dnch_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "dnch_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "dnch_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "dnch_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "dnch_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "dnch_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "dnch_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "meat_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "meat_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "meat_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "meat_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "meat_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "meat_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "meat_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "meat_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "ayib_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "ayib_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "ayib_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "ayib_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "ayib_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "ayib_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "kinche_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "kinche_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "kinche_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "kinche_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "kinche_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "kinche_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "kinche_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "rice_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "rice_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "rice_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "rice_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "rice_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "rice_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "rice_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "rice_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mitmita_1.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "mitmita_3.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mitmita_7.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "mitmita_8.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mitmita_2.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "mitmita_5.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n",
      "mitmita_4.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2B010>\n",
      "mitmita_6.jpeg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x7FA54DE2AFB0>\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = \"./output/train/\"\n",
    "\n",
    "# Set the desired target size for resizing\n",
    "target_size = (256, 256)  # Adjust as per your requirements\n",
    "\n",
    "# Iterate over the image files in the directory\n",
    "for filename in os.listdir(train_data_dir):\n",
    "    image_dir = os.path.join(train_data_dir,filename)\n",
    "    for image in os.listdir(image_dir):\n",
    "        print(image)\n",
    "        if image.endswith('.jpeg'):\n",
    "            # Open the image\n",
    "            image_path = os.path.join(image_dir, image)\n",
    "            image = Image.open(image_path)\n",
    "            print(image)\n",
    "\n",
    "            # Resize the image\n",
    "            resized_image = image.resize(target_size)\n",
    "\n",
    "            # Save the resized image\n",
    "            resized_image.save(image_path)\n",
    "            \n",
    "             # Normalize pixel values\n",
    "            normalized_image = np.array(image) / 255.0\n",
    "\n",
    "            # Convert the pixel values back to the range [0, 255]?\n",
    "            normalized_image = (normalized_image * 255).astype(np.uint8)\n",
    "\n",
    "            # Save the normalized image\n",
    "            normalized_image = Image.fromarray(normalized_image)\n",
    "            normalized_image.save(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# # Set the path to your training directory\n",
    "# train_dir = \"./output/train/\"\n",
    "\n",
    "# # Set the image dimensions and batch size\n",
    "# image_size = (256, 256)\n",
    "# batch_size = 32\n",
    "\n",
    "# # Function to perform random rotation\n",
    "# def random_rotation(image):\n",
    "#     angle = random.randint(-20, 20)  # Random rotation angle between -20 and 20 degrees\n",
    "#     height, width = image.shape[:2]\n",
    "#     rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "#     rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "#     return rotated_image\n",
    "\n",
    "# # Function to perform random horizontal flip\n",
    "# def random_horizontal_flip(image):\n",
    "#     return cv2.flip(image, 1)  # Flip horizontally (axis=1)\n",
    "\n",
    "# # Function to perform random zoom\n",
    "# def random_zoom(image):\n",
    "#     zoom_range = random.uniform(0.8, 1.2)  # Random zoom range between 0.8 and 1.2\n",
    "#     height, width = image.shape[:2]\n",
    "#     zoom_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), 0, zoom_range)\n",
    "#     zoomed_image = cv2.warpAffine(image, zoom_matrix, (width, height))\n",
    "#     return zoomed_image\n",
    "\n",
    "# # Load the training dataset\n",
    "# train_images = []\n",
    "# train_labels = []\n",
    "\n",
    "# # Iterate through the training directory and load images\n",
    "# for class_name in os.listdir(train_dir):\n",
    "#     class_dir = os.path.join(train_dir, class_name)\n",
    "#     if os.path.isdir(class_dir):\n",
    "#         for image_name in os.listdir(class_dir):\n",
    "#             image_path = os.path.join(class_dir, image_name)\n",
    "#             image = cv2.imread(image_path)\n",
    "#             image = cv2.resize(image, image_size)\n",
    "#             train_images.append(image)\n",
    "#             train_labels.append(class_name)\n",
    "\n",
    "# # Perform data augmentation on the training data\n",
    "# augmented_images = []\n",
    "# augmented_labels = []\n",
    "\n",
    "# for image, label in zip(train_images, train_labels):\n",
    "#     augmented_images.append(image)\n",
    "#     augmented_labels.append(label)\n",
    "\n",
    "#     augmented_images.append(random_rotation(image))\n",
    "#     augmented_labels.append(label)\n",
    "\n",
    "#     augmented_images.append(random_horizontal_flip(image))\n",
    "#     augmented_labels.append(label)\n",
    "\n",
    "#     augmented_images.append(random_zoom(image))\n",
    "#     augmented_labels.append(label)\n",
    "\n",
    "# # Convert the augmented data to numpy arrays\n",
    "# augmented_images = np.array(augmented_images)\n",
    "# augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "# # Shuffle the augmented data\n",
    "# indices = np.arange(len(augmented_images))\n",
    "# np.random.shuffle(indices)\n",
    "# augmented_images = augmented_images[indices]\n",
    "# augmented_labels = augmented_labels[indices]\n",
    "\n",
    "\n",
    "# # Continue with building and training your model using augmented_images and augmented_labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# # Initialize the CNN\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add the convolutional layer\n",
    "# # filters, size of filters, padding, activation_function, input_shape\n",
    "# model.add(Conv2D(32, (5,5), padding='same', activation='relu', input_shape=(64, 64, 3)))\n",
    "\n",
    "# # Pooling layer\n",
    "# # pool_size\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # Add another convolutional layer\n",
    "# model.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "\n",
    "# # Pooling layer\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # Flattening layer\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Add a fully connected layer\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# # Output Layer\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the CNN\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the CNN\n",
    "# model.fit(X_train, y_train, batch_size=32, epochs=25, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255, rotation=40, width_shift=0.2, height_shift=0.2, shear=0.2, zoom=0.2, horizontal_flip=True,)\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=32, class_mode='binary')\n",
    "# validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150, 150), batch_size=32, class_mode='binary')\n",
    "# history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100, validation_data=validation_generator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 21:14:25.146737: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 21:14:34.168589: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-21 21:14:34.168722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-21 21:14:35.122324: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-21 21:14:38.885771: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 21:14:38.888927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 21:14:55.169222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 197 images belonging to 18 classes.\n",
      "Found 92 images belonging to 18 classes.\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.8259WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6 batches). You may need to use the repeat() function when building your dataset.\n",
      "6/6 [==============================] - 9s 996ms/step - loss: 0.3522 - accuracy: 0.8259 - val_loss: 0.2236 - val_accuracy: 0.9444\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 3s 626ms/step - loss: 0.2422 - accuracy: 0.9444\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 4s 535ms/step - loss: 0.2517 - accuracy: 0.9444\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.2402 - accuracy: 0.9444\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 3s 504ms/step - loss: 0.2384 - accuracy: 0.9444\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 4s 577ms/step - loss: 0.2597 - accuracy: 0.9444\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 3s 459ms/step - loss: 0.2458 - accuracy: 0.9444\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 3s 518ms/step - loss: 0.2480 - accuracy: 0.9444\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 4s 593ms/step - loss: 0.2335 - accuracy: 0.9444\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 3s 601ms/step - loss: 0.2352 - accuracy: 0.9444\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 3s 465ms/step - loss: 0.2360 - accuracy: 0.9444\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 3s 462ms/step - loss: 0.2337 - accuracy: 0.9444\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 3s 604ms/step - loss: 0.2456 - accuracy: 0.9444\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.2361 - accuracy: 0.9444\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 3s 508ms/step - loss: 0.2358 - accuracy: 0.9444\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 3s 628ms/step - loss: 0.2269 - accuracy: 0.9444\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.2291 - accuracy: 0.9444\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 3s 460ms/step - loss: 0.2293 - accuracy: 0.9444\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 3s 465ms/step - loss: 0.2343 - accuracy: 0.9444\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 4s 542ms/step - loss: 0.2434 - accuracy: 0.9444\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 3s 470ms/step - loss: 0.2291 - accuracy: 0.9444\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.2303 - accuracy: 0.9444\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.2330 - accuracy: 0.9444\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.2253 - accuracy: 0.9444\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 3s 464ms/step - loss: 0.2265 - accuracy: 0.9444\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 0.2313 - accuracy: 0.9444\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 3s 480ms/step - loss: 0.2298 - accuracy: 0.9444\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 4s 568ms/step - loss: 0.2319 - accuracy: 0.9444\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 4s 541ms/step - loss: 0.2260 - accuracy: 0.9444\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 4s 572ms/step - loss: 0.2225 - accuracy: 0.9444\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 3s 474ms/step - loss: 0.2276 - accuracy: 0.9444\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 3s 461ms/step - loss: 0.2262 - accuracy: 0.9444\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.2283 - accuracy: 0.9444\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 4s 553ms/step - loss: 0.2271 - accuracy: 0.9444\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 3s 489ms/step - loss: 0.2268 - accuracy: 0.9444\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.2281 - accuracy: 0.9444\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 3s 644ms/step - loss: 0.2271 - accuracy: 0.9444\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 3s 470ms/step - loss: 0.2277 - accuracy: 0.9444\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 4s 602ms/step - loss: 0.2243 - accuracy: 0.9444\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.2247 - accuracy: 0.9444\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 3s 648ms/step - loss: 0.2263 - accuracy: 0.9444\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.2260 - accuracy: 0.9444\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 4s 526ms/step - loss: 0.2254 - accuracy: 0.9444\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 4s 603ms/step - loss: 0.2250 - accuracy: 0.9444\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 3s 523ms/step - loss: 0.2242 - accuracy: 0.9444\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 3s 466ms/step - loss: 0.2252 - accuracy: 0.9444\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 3s 445ms/step - loss: 0.2252 - accuracy: 0.9444\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 3s 465ms/step - loss: 0.2256 - accuracy: 0.9444\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 3s 482ms/step - loss: 0.2442 - accuracy: 0.9444\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.2254 - accuracy: 0.9444\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 0.2157 - accuracy: 0.9444\n",
      "Test Loss: 0.21567822992801666\n",
      "Test Accuracy: 0.9444444179534912\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# load image data from the training directory\n",
    "train_data = datagen.flow_from_directory(\n",
    "        './output/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# load image data from the test directory\n",
    "test_data = datagen.flow_from_directory(\n",
    "        './output/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "model.fit(\n",
    "        train_data,\n",
    "        steps_per_epoch=6,\n",
    "        epochs=50,\n",
    "        validation_data=test_data,\n",
    "        validation_steps=6\n",
    "        )\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "evaluation = model.evaluate(test_data)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n",
      "Predicted Class: 0\n",
      "Predicted Label: mekoreni\n",
      "Is Correct: False\n"
     ]
    }
   ],
   "source": [
    "# # Make predictions on new data\n",
    "# predictions = model.predict(new_data_generator)\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = './output/validation/mm.jpg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = np.argmax(predictions[0])  # Assuming a categorical output\n",
    "\n",
    "# Map the predicted class to its label (adjust as needed based on your classes)\n",
    "class_labels = {0: 'mekoreni', 1: 'ayib',2: 'beso', 3: 'dfinmisir',4: 'dnch', 5: 'erd',6: 'fish', 7: 'habeshagomen',8:\"injera\",9:\"kinche\",10:\"meat\",11:\"aterkik\",12:\"misir\",13:\"mitmita\",14:\"pasta\",15:\"rice\",16:\"shirofloor\",17:\"sigaatint\"}\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "# Print the predicted class or label\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "\n",
    "# Compare with the true label (replace 'true_label' with the actual true label)\n",
    "true_label = 'meat'  # Replace with the actual true label\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = (predicted_label == true_label)\n",
    "\n",
    "# Print the result\n",
    "print(\"Is Correct:\", is_correct)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
